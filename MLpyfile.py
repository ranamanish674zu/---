# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1623lmbqunoQtCD1f4b_oeqhjoZAQcWVI
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
from sklearn.tree import export_text
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Sohel&MeProject/teacher_rating_dataset_250_unique_indian_names.csv')

df.head()

df.tail()

# Display basic information about the dataset
print(df.info())

# Display summary statistics
print(df.describe())

# Check for missing values
print(df.isnull().sum())

# Drop rows with missing values (if any)
df.dropna(inplace=True)

# Data Preprocessing
# Encode categorical variables
label_encoder_subject = LabelEncoder()
label_encoder_grade_level = LabelEncoder()
df['Subject'] = label_encoder_subject.fit_transform(df['Subject'])
df['Grade_Level'] = label_encoder_grade_level.fit_transform(df['Grade_Level'])

# Visualize the distribution of ratings
import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(df['Overall_Rating'], bins=5, kde=True)
plt.title('Distribution of Overall Ratings')
plt.show()

# Visualize the correlation matrix
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

# Pairplot for selected columns
sns.pairplot(df[['Effectiveness', 'Fairness', 'Availability', 'Assessment_Quality', 'Clarity']])
plt.show()

# Select relevant features
selected_features = ['Effectiveness', 'Fairness', 'Availability', 'Assessment_Quality', 'Clarity', 'Subject', 'Grade_Level', 'Overall_Rating', 'Name', 'Teacher_ID']
df_selected = df[selected_features]

# Split the data into features (X) and target variable (y)
X = df_selected.drop(['Overall_Rating', 'Name', 'Teacher_ID'], axis=1)
y = df_selected['Overall_Rating']

# Normalize numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Model Training
model = DecisionTreeRegressor(random_state=42)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Fit the Decision Tree model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)
print(y_pred)

# Evaluate the model for regression
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Alternatively, you can use cross-validation for a more robust evaluation
cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')
cv_rmse = np.sqrt(-cv_scores)
print(f'Cross-validated RMSE: {cv_rmse.mean()}')

# For a decision tree, you can also visualize the tree structure
tree_rules = export_text(model, feature_names=X.columns.tolist())
print("Decision Tree Rules:\n", tree_rules)

# Example: Convert ratings into classes (you can adjust the threshold as needed)
threshold = 3.5
y_pred_class = (y_pred > threshold).astype(int)
y_test_class = (y_test > threshold).astype(int)

# Evaluate the classification performance
conf_matrix = confusion_matrix(y_test_class, y_pred_class)
classification_rep = classification_report(y_test_class, y_pred_class)

print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", classification_rep)

# Calculate accuracy
accuracy = np.mean(y_pred_class == y_test_class)
print(f'Accuracy: {accuracy}')





# Get user input for subject and grade level
subject_input = input("Enter the subject: ")
grade_level_input = input("Enter the grade level: ")

# Filter the dataframe based on subject and grade level
filtered_df = df_selected[(df_selected['Subject'] == label_encoder_subject.transform([subject_input])[0]) & (df_selected['Grade_Level'] == label_encoder_grade_level.transform([grade_level_input])[0])]

if filtered_df.empty:
    print(f"No data available for the specified subject '{subject_input}' and grade level '{grade_level_input}'.")
else:
    # Use the filtered dataset for training the model
    model.fit(X_scaled[y.index.isin(filtered_df.index)], y[y.index.isin(filtered_df.index)])

    # Prediction Function
    def predict_top_teachers(model, scaler, df, top_k=5):
        input_data = filtered_df[['Effectiveness', 'Fairness', 'Availability', 'Assessment_Quality', 'Clarity', 'Subject', 'Grade_Level']]
        input_scaled = scaler.transform(input_data)
        predicted_rating = model.predict(input_scaled)

        # Combine predictions with teacher names and IDs
        results = df[['Name', 'Teacher_ID', 'Overall_Rating']].copy()
        results['Predicted_Rating'] = model.predict(scaler.transform(df[['Effectiveness', 'Fairness', 'Availability', 'Assessment_Quality', 'Clarity', 'Subject', 'Grade_Level']]))

        # Select top teachers
        top_teachers = results.nlargest(top_k, 'Predicted_Rating')[['Name', 'Teacher_ID', 'Predicted_Rating']]

        return top_teachers

    # Example Usage
    top_teachers = predict_top_teachers(model, scaler, df_selected)
    print(top_teachers)